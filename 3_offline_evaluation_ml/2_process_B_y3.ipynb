{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43faa4d-db0f-4cd3-a093-19438ecae397",
   "metadata": {},
   "source": [
    "# Template Notebook\n",
    "Notebook template with the stucture of the notebook and some default codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922bd84-6691-4e5a-92c9-dac5fd7dadbd",
   "metadata": {},
   "source": [
    "## Root folder and read env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846b3c3-ef67-4a3c-8b9d-3b3796b61fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# fix root path to save outputs\n",
    "actual_path = os.path.abspath(os.getcwd())\n",
    "list_root_path = actual_path.split('\\\\')[:-1]\n",
    "root_path = '\\\\'.join(list_root_path)\n",
    "os.chdir(root_path)\n",
    "print('root path: ', root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c0576-ebc2-4df8-9bea-50f29844198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv # package used in jupyter notebook to read the variables in file .env\n",
    "\n",
    "\"\"\" get env variable from .env \"\"\"\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\"\"\" Read env variables and save it as python variable \"\"\"\n",
    "PROJECT_GCP = os.environ.get(\"PROJECT_GCP\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bab0f8-b9f4-4887-bd70-1790163eab22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddd36dbb-2fb7-4476-96ef-b1ef520e3133",
   "metadata": {},
   "source": [
    "## I) PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ac8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "import gcsfs\n",
    "import pickle\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# explanaible AI\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# #shap - shapash\n",
    "# import shap\n",
    "# from shapash import SmartExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30fb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "### desarrollo\n",
    "\n",
    "PROJECT_ID = PROJECT_GCP\n",
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e733877-c533-4b6b-ad74-bf2a25ad205a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac223d66-5de8-4ef0-a6d7-d78516ca34b4",
   "metadata": {},
   "source": [
    "## II) LOAD ARTIFACTS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fd9ce-0f6b-4a50-9cf6-882793846d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f123e686-ec3d-448e-957e-db98d5f06639",
   "metadata": {},
   "source": [
    "### 1. Load model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff66ce-df08-467d-878f-871be0fee925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model name that indicate what process it is modelling and not what kind of machine learning model was trained\n",
    "name_model = 'process_b_y3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0371aa-1d47-4903-9c14-128089937e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed17135c-4351-4d15-8180-1638682ae28c",
   "metadata": {},
   "source": [
    "### 2. Load data test (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b5fc0-a605-4553-90ce-6dd05d20663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "path_X_train = f'artifacts/data_training/{name_model}/X_train.pkl'\n",
    "X_train = pd.read_pickle(path_X_train)\n",
    "\n",
    "# y_train\n",
    "path_y_train = f'artifacts/data_training/{name_model}/y_train.pkl'\n",
    "y_train = pd.read_pickle(path_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4625c-a3af-4e9d-be39-6a85bc2277ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test\n",
    "path_X_test = f'artifacts/data_training/{name_model}/X_test.pkl'\n",
    "X_test = pd.read_pickle(path_X_test)\n",
    "\n",
    "# y_test\n",
    "path_y_test = f'artifacts/data_training/{name_model}/y_test.pkl'\n",
    "y_test = pd.read_pickle(path_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c459e16-ac0c-4656-b6f3-9e5f5f051820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SHAPE DATA')\n",
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "\n",
    "print('\\n')\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11aea81-a55c-465c-a36c-8232b424cee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1993498-8dfc-473c-a67b-13b467ba7ae4",
   "metadata": {},
   "source": [
    "### 3. Load model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3839d-5d33-46e5-97bf-adf66ca4e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "path_model = f'artifacts/models/{name_model}/model.pkl'\n",
    "model = pd.read_pickle(path_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86913a7-c303-4c7f-953e-c596eff7ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a string with the name of the kind of machine learning model was trained\n",
    "model_type_string = 'Linear Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f96cd3-0513-4c59-a18d-710641960df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a model name and type of model\n",
    "name_model_and_type = name_model + '//' + model_type_string\n",
    "name_model_and_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f535ccf-fe0d-4adf-9456-5419db7af5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ff211-8dfb-4db2-9790-0066df2be1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "410c10dc-bc59-46a0-bc2c-87bb7627c800",
   "metadata": {},
   "source": [
    "### 4. Load list features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787fb57-a8c7-45af-8255-2c364214bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_features_target_to_optimization = f'config/optimization_engine/ml_models/MasterTable_{name_model}.xlsx'\n",
    "maestro_tags = pd.read_excel(path_list_features_target_to_optimization)\n",
    "maestro_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b7eb9-868c-4320-ac21-8a8cfcc6d721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2ad53c6-511c-42c0-9faf-87787f792c10",
   "metadata": {},
   "source": [
    "## III) OFFLINE EVALUATION MODEL\n",
    "The offline evaluation of the model consist in evaluate how the model perform with its metrics and how the model will perform using to create a prescriptive machine learning systems. To achieve that not only the mean metrics with all data matters, also it is neccesary to see how to model perform into a delta change in the values, the model can generalize the data but not overtitting it, if there is some group of data that the model doesn't work, etc\n",
    "\n",
    "The list of offline evaluation are:\n",
    "\n",
    "1. Metrics\n",
    "\n",
    "2. Plots predictions\n",
    "\n",
    "3. Explanaible AI\n",
    "\n",
    "4. Peturbation tests / Sensitivy Analysis\n",
    "\n",
    "5. Metrics by segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbbe08b-3eae-417e-baa6-438a35e93342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8dbb04c-891a-4aee-b657-c902ba80ffa0",
   "metadata": {},
   "source": [
    "### 0. Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccc2e5-b07c-4f66-b517-d7e8b359b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# transform dataframe\n",
    "y_test_pred = pd.DataFrame(y_test_pred)\n",
    "y_test_pred.columns = y_test.columns\n",
    "y_test_pred.index = y_test.index\n",
    "\n",
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ea676-e34a-4821-9c6b-628b83104cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa57c43-e82f-46fe-ab05-9640a3f9736d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63116377-3e14-439c-8a1f-e78ca486c2e4",
   "metadata": {},
   "source": [
    "### 1. Metrics\n",
    "**Group 1 R2**\n",
    "- R2\n",
    "\n",
    "**Group 2 MSE**\n",
    "- MSE\n",
    "\n",
    "**Group 3 RMSE**\n",
    "- RMSE\n",
    "- RMSE MEAN RATIO (rmse mean ratio: rmse / mean_y_true)\n",
    "- RMSE IQR RATIO (rmse iqr ratio: rmse / iqr_y_true)\n",
    "\n",
    "**Group 4 MAE**\n",
    "- MAE\n",
    "- MAE MEAN RATIO\n",
    "- MAE IQR RATIO\n",
    "\n",
    "------\n",
    "Calculating metrics for:\n",
    "- Model trained\n",
    "- Basic Model - mean target / predict common class\n",
    "- Baseline Model\n",
    "- Last best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ba707-b97f-4cf9-a316-7cba6bdacc1e",
   "metadata": {},
   "source": [
    "#### 1.1 Metric for Model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77999ff7-307c-4199-9816-898c3522844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_regressors_models(y, y_pred, model_name, decimals_round = None):\n",
    "    \"\"\"\n",
    "    Calculate a certain number of metrics to evaluate regression models. The metrics are rounded to X decimals\n",
    "\n",
    "    Args\n",
    "        y (dataframe): y true\n",
    "        y_pred (dataframe): y predicted with the model. In this codes are passed y_pred instead of X\n",
    "        model_name (string): name of the model. This name is used when the metrics are saved to identify the model of these metrics\n",
    "        decimals_round = Number of decimals to round the values. Defult None, no round the values.\n",
    "\n",
    "    Return\n",
    "        metrics_regressors (dataframe): dataframe with the metrics of the model in this datasets. Row: name metrics. Columns: value metrics\n",
    "    \"\"\"\n",
    "\n",
    "    #### R2\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    #### MSE\n",
    "    mse = mean_squared_error(y, y_pred, squared = True)\n",
    "    \n",
    "    #### RMSE\n",
    "    rmse = mean_squared_error(y, y_pred, squared = False)\n",
    "    \n",
    "    #### RMSE_MEAN_RATIO\n",
    "    # rmse mean ratio: rmse / mean_y_true\n",
    "    rmse_mean_ratio = rmse / y.mean().values[0]\n",
    "    rmse_mean_ratio = round(100 * (rmse_mean_ratio), 2)\n",
    "    \n",
    "    #### RMSE_IQR_RATIO\n",
    "    # rmse iqr ratio: rmse / iqr_y_true\n",
    "    rmse_iqr_ratio = rmse / iqr(y)\n",
    "    rmse_iqr_ratio = round(100 * (rmse_iqr_ratio), 2)\n",
    "    \n",
    "    #### MAE\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    #### MAE_RATIO\n",
    "    mae_mean_ratio = mae / y.mean().values[0]\n",
    "    mae_mean_ratio = round(100 * (mae_mean_ratio), 2)\n",
    "    \n",
    "    #### MAE_IQR_RATIO\n",
    "    mae_iqr_ratio = mae / iqr(y)\n",
    "    mae_iqr_ratio = round(100 * (mae_iqr_ratio), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### JOIN INTO ONE DATAFRAME\n",
    "    # create dataframe\n",
    "    metrics_regressors = pd.DataFrame(index = [model_name])\n",
    "    \n",
    "    # add metrics\n",
    "    metrics_regressors['r2'] = r2\n",
    "    metrics_regressors['mse'] = mse\n",
    "    metrics_regressors['rmse'] = rmse\n",
    "    metrics_regressors['rmse_mean_ratio(%)'] = rmse_mean_ratio\n",
    "    metrics_regressors['rmse_iqr_ratio(%)'] = rmse_iqr_ratio\n",
    "    metrics_regressors['mae'] = mae\n",
    "    metrics_regressors['mae_mean_ratio(%)'] = mae_mean_ratio\n",
    "    metrics_regressors['mae_iqr_ratio(%)'] = mae_iqr_ratio\n",
    "    \n",
    "    # round\n",
    "    metrics_regressors = metrics_regressors.astype('float')\n",
    "    if decimals_round:\n",
    "        metrics_regressors = metrics_regressors.round(decimals_round)\n",
    "\n",
    "\n",
    "    return metrics_regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e46d6-942e-4422-9ce7-f268d80c7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics_regressors_models(y = y_test, \n",
    "                                              y_pred = y_test_pred, \n",
    "                                              model_name = name_model_and_type, \n",
    "                                              decimals_round = None\n",
    "                                             )\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8804a-c23d-4cb8-b1c3-b9441c2cde72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e08c42c-45d0-4679-a158-b7e821ab0ce3",
   "metadata": {},
   "source": [
    "#### 1.2 Basic Model - mean target / predict common class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a661c-1aa5-4ae4-b0f0-c23361f7cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean y train. ADJUST BASIC MODEL\n",
    "y_basic_model = y_train.mean().values[0]\n",
    "y_basic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b8a04-04de-48b7-9384-a1271cd4937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vector to y_pred to evaluate. obs generate len according the y_true when the mean prediction will be compared\n",
    "y_basic_model_pred = pd.DataFrame(y_basic_model * np.ones([y_test.shape[0]]))\n",
    "y_basic_model_pred.index = y_test.index\n",
    "y_basic_model_pred.columns = y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f93585-fedf-4abf-94d9-02101e7f3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics basic model\n",
    "metrics_basic_model = calculate_metrics_regressors_models(y = y_test, \n",
    "                                                          y_pred = y_basic_model_pred, \n",
    "                                                          model_name = 'd0eop_microkappa//Basic Model Pred', \n",
    "                                                          decimals_round = None\n",
    "                                                         )\n",
    "metrics_basic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611cd82-3d5f-4711-86f3-6586211411b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ab00702-94ea-44da-a582-ec1893ba6418",
   "metadata": {},
   "source": [
    "#### 1.3 Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be5f81c-8222-424f-bc61-930a145518e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed088703-fe13-413b-ba06-261d13295918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e12fc46a-aed4-4f45-97ed-c93c565adebb",
   "metadata": {},
   "source": [
    "#### 1.4 Last best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c7f6e-9fa0-4b96-868e-dea4e442d629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd92d2-3b6c-45e3-8552-769da727339b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "525025de-91a9-488d-8480-13be9289b6bf",
   "metadata": {},
   "source": [
    "### 2. Plot Predictions\n",
    "- y_true vs y_pred\n",
    "- hist_errors\n",
    "- trend_errors\n",
    "- features vs errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c28e8-c74a-46de-8ea5-ed77131fcb0d",
   "metadata": {},
   "source": [
    "#### 2.1 y_true vs y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e18da-a740-4e55-8cbb-700cf4caf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_y_true_vs_y_pred(y, y_pred, title_plot):\n",
    "    \"\"\"\n",
    "    Plot y_true vs y_pred (using matplotlib figure). y_true in X-axis, y_pred in Y-axis.\n",
    "\n",
    "    Args:\n",
    "        y (dataframe): dataframe with y-true values \n",
    "        y_pred (dataframe): dataframe with y-pred values\n",
    "        title_plot (string): tittle in the plot\n",
    "    \n",
    "    Return\n",
    "        fig (figure matplolib): figure to show, download, etc\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    scatter_plot = ax.scatter(y, y_pred, alpha=0.3, marker='x', label='y_true vs y_pred')\n",
    "\n",
    "    # Add bisectriz\n",
    "    y_bisectriz = x_bisectriz = np.linspace(y.min()[0], y.max()[0], y.shape[0])\n",
    "    ax.plot(x_bisectriz, y_bisectriz, label='Bisectriz', color='red', alpha=0.3)\n",
    "\n",
    "    # Add names to axis\n",
    "    ax.set_xlabel('Y true')\n",
    "    ax.set_ylabel('Y pred')\n",
    "    \n",
    "    ax.set_title(title_plot)\n",
    "    ax.legend()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cdad0-754e-4035-9ad6-de333ecafb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_y_pred = plot_y_true_vs_y_pred(y = y_test, \n",
    "                                      y_pred = y_test_pred, \n",
    "                                      title_plot = name_model_and_type\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa96e29-cae9-4129-83dc-7d83c7615731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e1f5dc-4e7b-4ec0-814c-bc7aba308951",
   "metadata": {},
   "source": [
    "#### 2.2 hist errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b743387-dad9-4cea-85c2-bd3bb041d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_errors_predictions(y, y_pred, title_plot, n_bins = 10):\n",
    "    \"\"\"\n",
    "    Plot histogram of error in prediction: errors: abs(y_true vs y_pred) (using matplotlib figure)\n",
    "\n",
    "    Args:\n",
    "        y (dataframe): dataframe with y-true values \n",
    "        y_pred (dataframe): dataframe with y-pred values\n",
    "        title_plot (string): tittle in the plot\n",
    "        n_bins (integer): number of bins in the histogram. Default = 10\n",
    "    \n",
    "    Return\n",
    "        fig (figure matplolib): figure to show, download, etc\n",
    "    \"\"\"\n",
    "    # calculate error\n",
    "    errors = y - y_pred\n",
    "    errors = np.abs(errors) # error in abs value\n",
    "    \n",
    "    # hist error\n",
    "    fig = plt.figure()\n",
    "    plt.hist(errors, bins = n_bins)\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Freq')\n",
    "    plt.title(f'Histogram of Errors in Predictions:  abs(y - y_pred) - {title_plot}')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac763d-36e7-4f71-b64b-5011da6d172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_errors = hist_errors_predictions(y = y_test, \n",
    "                                      y_pred = y_test_pred, \n",
    "                                        title_plot = name_model_and_type\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0f60f-1c8e-4cae-b2a5-670d0870f92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aafb71f-ca83-438a-bbe8-531da1d5c1e1",
   "metadata": {},
   "source": [
    "#### 2.3 Trend Errors\n",
    "The split of the data was randomly instead of time split. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812100e-aede-43ca-856f-787e0b75359f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab50339-3f45-4688-a569-d12a67135a68",
   "metadata": {},
   "source": [
    "#### 2.4 Features vs Errors\n",
    "Plotear los errores para cada una de las observaciones de los datos. En el eje X se muestra los valores de una feature en concreto (pero no del resto de features que acompañan esta instancia). Son todos valores reales. La idea busca imitar a un PDP pero en lugar de utilizar los valores promedios del rsto de features se utilizan los valores reales\n",
    "\n",
    "Intuición del gráfico\n",
    "- La idea es poder terminar por ejemplo, si justo en los datos cuando las condiciones reales de operación se ven representadas por una feature X > 1000 siempre los errores son más altos\n",
    "\n",
    "- Por ejemplo que la distribución del error en algunos segmentos sea notoriamente más alta. Se podría plantear separar el modelo hacer hacer foco en estas predicciones con los errores más altos\n",
    "\n",
    "- Inspirado en tratar de replicar de cierta forma modelos por tramos y los modelos de boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac83378-523e-44f0-b487-7b8a1d5c5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors_vs_one_feature(X, y, y_pred, title_plot, list_features, abs_error):\n",
    "    \"\"\"\n",
    "    Plot errors vs features.\n",
    "\n",
    "    Args:\n",
    "        X (dataframe): dataframe with X true values - features\n",
    "        y (dataframe): dataframe with y-true values \n",
    "        y_pred (dataframe): dataframe with y-pred values\n",
    "        title_plot (string): tittle in the plot\n",
    "        list_features (list): list of features that will plot againts the errrors. The features needs to be present in the data\n",
    "        abs_error (boolean): True: Plot the absolute value of the errors abs(y_true - y_pred). False: Plot y_true - y_pred\n",
    "    \n",
    "    Return\n",
    "        fig (figure matplolib): figure to show, download, etc\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate error\n",
    "    errors = y - y_pred # error\n",
    "    errors_abs = np.abs(errors) # errors in abs value\n",
    "    if abs_error:\n",
    "        errors_to_plot = errors_abs\n",
    "    else:\n",
    "        errors_to_plot = errors\n",
    "\n",
    "    # for in features\n",
    "    for feature in list_features:\n",
    "\n",
    "        fig = plt.Figure()\n",
    "        plt.scatter(X[feature],  # feature\n",
    "                   errors_to_plot,  # errors y_true - y_pred\n",
    "                    alpha = 0.5\n",
    "                   )\n",
    "        \n",
    "        # Add names to axis\n",
    "        plt.xlabel(f'Feature: {feature}')\n",
    "        plt.ylabel('Errors y')\n",
    "\n",
    "        plt.title(title_plot)\n",
    "        #plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94326b-b521-4877-b93a-134c49c82a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "erorrs_vs_features = plot_errors_vs_one_feature(X = X_test,\n",
    "                                                y = y_test, \n",
    "                                                y_pred = y_test_pred, \n",
    "                                                title_plot = name_model_and_type,\n",
    "                                                list_features = X_test.columns.tolist(), \n",
    "                                                abs_error = True\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa783b3-cf24-4f36-97b8-0afbd0fe3c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a39b1f4b-a213-4188-a638-4e925b493b67",
   "metadata": {},
   "source": [
    "### 3. Explanaible AI\n",
    "Hay muchas herramientas de explanaible AI. Aquí se muestran las más clásicas (y utilizando las implementaciones de sklearn cuando es posible). Herramientas:\n",
    "- Permutation Importances\n",
    "- Permutation Importances with Noise Features\n",
    "- Partial Depende Plots (PDP)\n",
    "- Shapley values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927db53-a735-4bfa-a157-f51dcc684065",
   "metadata": {},
   "source": [
    "#### 3.1 Permutation Importances\n",
    "- Obtener la importancia de las variables luego de realizar permutaciones en cada feature de forma individual y observar cómo varía el poder predictivo del modelo\n",
    "- The estimator is required to be a fitted estimator. X can be the data set used to train the estimator or a hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3d81a-0e93-4cd2-9037-40dc88e7cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate permutation importances\n",
    "results = permutation_importance(estimator = model, \n",
    "                                 X = X_test, \n",
    "                                 y = y_test, \n",
    "                                 n_repeats = 30,\n",
    "                                 random_state = 42\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6246340-7061-43fa-b23e-3f3349fc30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a series with importances (mean) of each feature\n",
    "list_feartures_tag_description =maestro_tags[maestro_tags['CLASIFICACION'] != 'T']['FEATURES_NAMES'].tolist()\n",
    "df_importances = pd.Series(results.importances_mean, index = list_feartures_tag_description )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce212b5-f767-43fe-8cd2-447f43bda7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "df_importances.plot.bar(yerr = results.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation\")\n",
    "ax.set_ylabel(\"Mean R2 decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cee04b-6edd-4ddd-bfb4-b86b9930eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "maestro_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f67b1-cc66-4683-91de-2c0a540cc61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c4225-6b1b-4ef7-8cf4-b452a9247d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff1512a-ecf0-4005-a905-2953c9dcdd73",
   "metadata": {},
   "source": [
    "#### 3.2 Permutation Importances with Noise Features\n",
    "- Entrenar modelos de ML con 1-2 features que son solo ruido - Distribución Normal con Media 0 y Varianza 1\n",
    "- Poder evaluar si el modelo utilizado es tan potente que es capaz de ajustarse al ruido y determinar estas variables como más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8942877-55c2-446f-b921-f6c7feacc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance model and data noise since original instance model trained\n",
    "import copy\n",
    "model_noise = copy.deepcopy(model)\n",
    "\n",
    "X_train_noise = X_train.copy()\n",
    "y_train_noise = y_train.copy()\n",
    "X_test_noise = X_test.copy()\n",
    "y_test_noise = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7dd77-99ae-41d3-9d22-297b22a93c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe train - test with noise\n",
    "np.random.seed(42)\n",
    "X_train_noise['noise_1'] = np.random.normal(size = X_train.shape[0])\n",
    "X_train_noise['noise_2'] = 10 * np.random.normal(size = X_train.shape[0])\n",
    "\n",
    "X_test_noise['noise_1'] = np.random.normal(size = X_test.shape[0])\n",
    "X_test_noise['noise_2'] = 10 * np.random.normal(size = X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663ba0a-f2b4-44d7-bc75-ed6a328ae1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model_noise.fit(X_train_noise, y_train_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230575d-6ac6-4728-8691-ae0ef9c3ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "y_test_noise_pred = model_noise.predict(X_test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e24fd-470d-4ea1-821b-0c546d928abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PDP - utilizar funcion anterior - re utilizar funcion\n",
    "\n",
    "# calculate permutation importances\n",
    "results = permutation_importance(estimator = model_noise, \n",
    "                                 X = X_test_noise, \n",
    "                                 y = y_test_noise, \n",
    "                                 n_repeats = 30,\n",
    "                                 random_state = 42\n",
    "                                )\n",
    "\n",
    "# define a series with importances (mean) of each feature\n",
    "#list_feartures_tag_description =maestro_tags[maestro_tags['CLASIFICACION'] != 'T']['FEATURES_NAMES'].tolist()\n",
    "df_importances = pd.Series(results.importances_mean, index = X_test_noise.columns.tolist() )\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "df_importances.plot.bar(yerr = results.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation\")\n",
    "ax.set_ylabel(\"Mean R2 decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e0d12-56de-4ddf-8533-81bfd901dfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5b391-521c-4e68-ae2e-56dca2efade3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd07f006-3844-4f65-a6f0-a887f5061f96",
   "metadata": {},
   "source": [
    "#### 3.3 Partial Dependence Plot\n",
    "Gráficos de dependencia parcial. Mostrar cómo cambian los valores de la predicción dado el cambio de los valores de una feature mientras se mantiene el resto en sus valores medios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c18061-ccda-4a67-8215-ee9a2fc1c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP - all features\n",
    "\n",
    "# plot\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    estimator = model,\n",
    "    X = X_test,\n",
    "    random_state = 42,\n",
    "    features = X_test.columns.tolist(),\n",
    "    n_cols = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3826a-a23a-465f-9c8a-77551c83ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una figura con el tamaño deseado\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Mostrar el gráfico\n",
    "display.plot(ax=plt.gca())  # Utiliza el eje actual de la figura actual\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b84ef-49f2-4624-ab93-43f9b858f716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fb008-c88a-4b98-b63b-24351d6e49a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8897a52b-32a1-44da-86a4-5421ea7f5c63",
   "metadata": {},
   "source": [
    "#### 3.4 Shapley Values\n",
    "Plots utilizando el package SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7bf7a-42cf-4310-8219-69db7ccf3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO - shap values\n",
    "# TO DO - shapash package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794393bf-3450-4258-a36c-cb517f738741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d077f9-5e34-4f6f-a0e3-d603e98a3c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ace42a-5578-4eb3-ba6a-a3110706aa95",
   "metadata": {},
   "source": [
    "### 4. Perturbation test - Sensitivy Analysis\n",
    "The idea of this is to analyze the effect on the predictions by adding small perturbations to the data (small perturbation on a feature).\n",
    "\n",
    "For example, having the model y = f(x1, x2, x3). The goal is to answer the questions, what if I make a small modification to the feature x1, how will the model prediction change with this small perturbation (a priori this small perturbation does not affect the prediction)?\n",
    "\n",
    "In these projects, where the goal is to use machine learning models to generate recommendations (prescriptive analysis), it is necessary that the model can generalize sufficiently because the optimizer will change the values of the features looking for the optimal value to maximize this objective function.\n",
    "\n",
    "**OBS: these are my codes and my ideas (searching a package that do that). The user set an epsilon variation in a specific feature. Then the codes generate two dataframe with \"feature +- epsilon\" and get the preditions with this variations. Finally generate a plot with \"\"preditions, predictions_plus_epsilon, preditions_minus_epsilon\"\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d163b13-58e3-4456-8276-65a84ed73878",
   "metadata": {},
   "source": [
    "#### 4.1 Peturbation test one feature global plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc560d5-b09f-45b9-8839-93cceb2854ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbation_test_one_feature_global_analysis(tag_sensitivy_analysis, epsilon, X, y, y_pred):\n",
    "    \"\"\"\n",
    "    (Perturbation +- epsilon) in one feature and predict with this perturbations. Plot a histogram of predited values with\n",
    "    \"true values\", \"pred values\", \"pred values - epsilon\" and \"pred values + epsilon\"\n",
    "\n",
    "    Args\n",
    "        tag_sensitivy_analysis (string): tag sensitivy analysis\n",
    "        epsilon (float/integer): epsilon perturbation in the data\n",
    "        X (dataframe): features dataframe\n",
    "        y (dataframe): target dataframe (true values)\n",
    "        y_pred (dataframe): target predicted dataframe (prediction without perturbation)\n",
    "\n",
    "    Return\n",
    "        plot\n",
    "    \"\"\"\n",
    "    \n",
    "    ###### get list of original features\n",
    "    list_original_features = X.columns.tolist()\n",
    "    \n",
    "    ###### clone data\n",
    "    X_sensitivy = X.copy()\n",
    "    y_pred_sensitivy = y_pred.copy()\n",
    "    y_pred_sensitivy.columns = ['target']\n",
    "    \n",
    "    ###### calculate the percentual variation of the epsilon in the feature (mean value). how is the percentual variation of the data\n",
    "    epsilon_percent_impact = round(100 * epsilon / X_sensitivy[tag_sensitivy_analysis].mean(), 2)\n",
    "    print(f'-- Epsilon percent impact: {epsilon_percent_impact}%')\n",
    "    \n",
    "    ###### generate two columns of the feature: (feature-epsilon, feature+epsilon)\n",
    "    X_sensitivy[tag_sensitivy_analysis + '_-_epsilon'] = X_sensitivy[tag_sensitivy_analysis] - epsilon\n",
    "    X_sensitivy[tag_sensitivy_analysis + '_+_epsilon'] = X_sensitivy[tag_sensitivy_analysis] + epsilon\n",
    "    \n",
    "    \n",
    "    ###### get the predicted values with the perturbation (feature-epsilon, feature+epsilon)\n",
    "    # clone list original features to reeplace the feature with epsilon values\n",
    "    list_features_minus_epsilon = list_original_features.copy()\n",
    "    list_features_plus_epsilon = list_original_features.copy()\n",
    "    \n",
    "    # get the position of the feature with sensitivy analysis\n",
    "    idx_tag_sensitivy_analysis = list_features_minus_epsilon.index(tag_sensitivy_analysis)\n",
    "    \n",
    "    # redefine list of features with the names of features with epsilon values\n",
    "    list_features_minus_epsilon[idx_tag_sensitivy_analysis] = tag_sensitivy_analysis + '_-_epsilon'\n",
    "    list_features_plus_epsilon[idx_tag_sensitivy_analysis] = tag_sensitivy_analysis + '_+_epsilon'\n",
    "    \n",
    "    ###### model.predict with its epsilon values\n",
    "    # generate data minus and plus\n",
    "    data_sensitivy_minus = X_sensitivy[list_features_minus_epsilon] # filter\n",
    "    data_sensitivy_minus.columns = list_original_features # rename columns\n",
    "    data_sensitivy_plus = X_sensitivy[list_features_plus_epsilon]\n",
    "    data_sensitivy_plus.columns = list_original_features\n",
    "    \n",
    "    # save predict values\n",
    "    y_pred_sensitivy['target_'+ '_-_epsilon'] = model.predict(data_sensitivy_minus) # predecir con delta minus de variable de \n",
    "    y_pred_sensitivy['target_'+ '_+_epsilon'] = model.predict(data_sensitivy_plus)\n",
    "    \n",
    "    \n",
    "    sns.kdeplot(y, label = 'true')\n",
    "    sns.kdeplot(y_pred_sensitivy['target'], label = 'pred')\n",
    "    sns.kdeplot(y_pred_sensitivy['target_'+ '_-_epsilon'], label = 'pred-epsilon(feature)')\n",
    "    sns.kdeplot(y_pred_sensitivy['target_'+ '_+_epsilon'], label = 'pred+epsilon(feature)')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316a9b9-3fd6-4e3e-a4c7-8661c87fa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOST_IMPORTANT_FEATURE = 'Z1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d0061-139f-48e4-b4d6-12539021bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_test_one_feature_global_analysis(tag_sensitivy_analysis = MOST_IMPORTANT_FEATURE, # most important feature for example\n",
    "                                              epsilon = 1, \n",
    "                                              X = X_test.copy(), \n",
    "                                              y = y_test.copy(), \n",
    "                                              y_pred = y_test_pred.copy()\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d6a71-3a5c-48d4-aad7-ed64429ebfad",
   "metadata": {},
   "source": [
    "#### 4.2 Peturbation test one feature individual analysis\n",
    "The idea here is analysis the efect of changing the values of one feature manually for one instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac18e34-ba7b-43cb-9be6-d213a5774df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base instance - real data\n",
    "instance_base = X_test.head(1)\n",
    "instance_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6aace0-0f5b-4ac0-b6f8-197827fc8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction base instance\n",
    "model.predict(instance_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4283d3-4775-4d2b-a944-78c5899212e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a perturbation in one feature. For example modifying chemicals\n",
    "instance_perturbation = instance_base.copy()\n",
    "instance_perturbation[MOST_IMPORTANT_FEATURE] = 6.1 # PERTURBATION\n",
    "instance_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387a20c-079d-4960-9f2f-637dcf6b0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict perburbation instance\n",
    "model.predict(instance_perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3849ab-b57d-45b2-b253-8972c0ee8ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365f7d6-a0a7-4fac-9306-5a7315c64237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6f83d-06e7-4d1e-8491-ab562695c94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1477728-3762-41c6-b1ff-92a3763fae70",
   "metadata": {},
   "source": [
    "### 5. Metrics by segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d6861-ff67-4f67-9d14-8ff1f3af1211",
   "metadata": {},
   "source": [
    "#### 5.0 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0795b0a-1333-492d-ba65-608638b123e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70647d86-85e3-4650-be21-aaa92e13dc76",
   "metadata": {},
   "source": [
    "#### 5.1 Segment by most important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49f916-33ef-4536-bcdc-90fcdeaf63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_segment = MOST_IMPORTANT_FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f0b8c-a14f-49f0-be6a-a8bfb98b8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentile and bins\n",
    "percentile_index, bins = pd.qcut(X_test[tag_segment], 5, labels=False, retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5d038-834b-4b78-8ae5-367071f5aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns percentile in y test\n",
    "y_test_percentile = y_test.copy()\n",
    "y_test_percentile['percentile_index'] = percentile_index\n",
    "\n",
    "# add columns percentile in y test pred\n",
    "y_test_pred_percentile = y_test_pred.copy()\n",
    "y_test_pred_percentile['percentile_index'] = percentile_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712e915-775d-4f7c-9df8-32d22c18daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show metrics\n",
    "metrics_percentile = pd.DataFrame()\n",
    "for index in range(5):\n",
    "    \n",
    "    # calculate values start and end\n",
    "    start_segment = round(bins[index], 3)\n",
    "    end_segment = round(bins[index+1], 3)\n",
    "    print(f' --------- --------- {index} --------- ---------')\n",
    "    print(f'VALOR INICIO FEATURE: {start_segment} // VALOR FIN FEATURE: {end_segment}')\n",
    "\n",
    "\n",
    "    # filter test data ground truth\n",
    "    y_test_percentile_aux = y_test_percentile[y_test_percentile['percentile_index'] == index]\n",
    "    y_test_percentile_aux = y_test_percentile_aux.drop(columns = 'percentile_index')\n",
    "\n",
    "    \n",
    "    # filter test data pred\n",
    "    y_test_pred_percentile_aux = y_test_pred_percentile[y_test_pred_percentile['percentile_index'] == index]\n",
    "    y_test_pred_percentile_aux = y_test_pred_percentile_aux.drop(columns = 'percentile_index')\n",
    "\n",
    "    \n",
    "    # calculate metrics\n",
    "    metrics_percentile_aux = calculate_metrics_regressors_models(y = y_test_percentile_aux,\n",
    "                                        y_pred = y_test_pred_percentile_aux, \n",
    "                                        model_name = f'Percentile {index}', \n",
    "                                        decimals_round = None\n",
    "                                       )\n",
    "\n",
    "    # append\n",
    "    metrics_percentile = pd.concat([metrics_percentile, metrics_percentile_aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536bac4d-47c2-45f0-818b-2a65c05d5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320f6fe-0ca4-42af-8916-9f90f2bd8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append original score\n",
    "pd.concat([metrics, metrics_percentile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e42bbb1-3c2e-49e1-bb9c-324d3f3f9403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b3732-374e-48fd-becb-7e1734f16294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d384d-fadc-472c-ac14-7d69d681a790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
